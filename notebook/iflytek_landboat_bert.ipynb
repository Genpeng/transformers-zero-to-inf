{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8aba45a-11fa-4055-957d-5f932945fd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from datasets import load_dataset, Value\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSequenceClassification, \n",
    "    TrainingArguments, \n",
    "    Trainer, \n",
    ")\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f07755ed-c5ed-4445-b2d4-f8e6414d4127",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28a01e0f-1c03-49c4-9d94-b4434d3b1498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data training arguments\n",
    "data_dir = \"data/iflytek/\"\n",
    "max_length = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a637d7e2-0d51-4a14-8957-7ecbb9251b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model arguments\n",
    "model_name = \"Langboat/mengzi-bert-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5694c5f2-7f19-42a7-8496-9b4bf2a1e719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training arguments\n",
    "output_dir = \"tmp/iflytek/\"\n",
    "overwrite_output_dir = True\n",
    "batch_size = 32\n",
    "num_train_epochs = 3\n",
    "learning_rate = 5e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e8eeb5-c025-4e7b-a240-3a91848e5602",
   "metadata": {},
   "source": [
    "# Step 1: Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b82e673e-d88a-43b1-ba2c-09665eeb3b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filepath = os.path.join(data_dir, \"train.json\")\n",
    "valid_filepath = os.path.join(data_dir, \"dev.json\")\n",
    "test_filepath = os.path.join(data_dir, \"test.json\")\n",
    "split_2_filepath = {\n",
    "    \"train\": train_filepath, \n",
    "    \"valid\": valid_filepath, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e59adb1a-d1f5-47bf-8638-57bf1c13989d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-e245dfba59b3c0bf\n",
      "Reusing dataset json (/home/studio-lab-user/.cache/huggingface/datasets/json/default-e245dfba59b3c0bf/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed3f673b2cd94be58adc5bc98a2dfa16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"json\", data_files=split_2_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8376696-e9e2-43e1-8f71-c02e30d86218",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/studio-lab-user/.cache/huggingface/datasets/json/default-e245dfba59b3c0bf/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426/cache-3c87beba9aa2c129.arrow\n",
      "Loading cached processed dataset at /home/studio-lab-user/.cache/huggingface/datasets/json/default-e245dfba59b3c0bf/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426/cache-432f08a282d4c3a1.arrow\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.cast_column(\"label\", Value(\"int32\"))\n",
    "dataset = dataset.rename_column(\"label_des\", \"label_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28a40b2a-f06d-47f2-83f0-034d996f91d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_id_2_label_name = {\n",
    "    int(label_id): label_name \n",
    "    for label_id, label_name in zip(dataset[\"train\"][\"label\"], dataset[\"train\"][\"label_name\"])\n",
    "}\n",
    "label_name_2_label_id = {\n",
    "    label_name: label_id \n",
    "    for label_id, label_name in label_id_2_label_name.items()\n",
    "}\n",
    "num_classes = len(label_id_2_label_name)\n",
    "label_names = [label_name for _, label_name in sorted(label_id_2_label_name.items(), key=lambda x: x[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e8f213-6100-4dd2-8b88-61ebd3a4a478",
   "metadata": {},
   "source": [
    "# Step 2: Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d44b7393-4f44-44bc-b476-45e25432eb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3849a304-ae35-4659-9ed5-7ef011932acd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 2769, 3221, 671, 1372, 2207, 916, 916, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"我是一只小俊俊\", padding=\"max_length\", truncation=True, max_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b62bf77-1025-429c-8cac-cdc240595a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/studio-lab-user/.cache/huggingface/datasets/json/default-e245dfba59b3c0bf/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426/cache-ae2a3cb2e4b69c9b.arrow\n",
      "Loading cached processed dataset at /home/studio-lab-user/.cache/huggingface/datasets/json/default-e245dfba59b3c0bf/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426/cache-5a29bab98e2db568.arrow\n"
     ]
    }
   ],
   "source": [
    "# tokenizer(...) returns a `BatchEncoding` instance\n",
    "dataset = dataset.map(\n",
    "    lambda batch: tokenizer(batch[\"sentence\"], padding=True, truncation=True, max_length=max_length), \n",
    "    batched=True, \n",
    "    batch_size=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4c516d-9dfe-4a26-ae5b-878c4bd929bd",
   "metadata": {},
   "source": [
    "# Step 3: Build our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2342a74f-7a91-4667-9fad-1a755bb036a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Langboat/mengzi-bert-base were not used when initializing BertForSequenceClassification: ['sop.cls.bias', 'sop.cls.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at Langboat/mengzi-bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_classes).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3049cf4-7591-441d-9fef-f0aa36d41a8a",
   "metadata": {},
   "source": [
    "# Step 4: Train & Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adc89805-5bfd-4770-85b2-beee18621917",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    y_true = pred.label_ids\n",
    "    y_pred = pred.predictions.argmax(axis=-1)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average=\"micro\")\n",
    "    return {\"accuracy\": acc, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da89f0e1-df65-472b-a2a9-ad022acca006",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging_steps = len(dataset[\"train\"]) // batch_size\n",
    "train_args = TrainingArguments(\n",
    "    output_dir=output_dir, \n",
    "    overwrite_output_dir=overwrite_output_dir, \n",
    "    do_train=True, \n",
    "    do_eval=True, \n",
    "    evaluation_strategy=\"epoch\", \n",
    "    per_device_train_batch_size=batch_size, \n",
    "    per_device_eval_batch_size=batch_size, \n",
    "    num_train_epochs=num_train_epochs, \n",
    "    learning_rate=learning_rate, \n",
    "    logging_steps=logging_steps, \n",
    "    log_level=\"error\", \n",
    "    disable_tqdm=False, \n",
    "    push_to_hub=False, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "482dbf36-3f0d-4b70-b203-1652abed8a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    tokenizer=tokenizer, \n",
    "    model=model, \n",
    "    compute_metrics=compute_metrics, \n",
    "    args=train_args, \n",
    "    train_dataset=dataset[\"train\"], \n",
    "    eval_dataset=dataset[\"valid\"], \n",
    ")\n",
    "# fix bug: \n",
    "# RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!\n",
    "old_data_collator = trainer.data_collator  # `DataCollatorWithPadding` instance\n",
    "trainer.data_collator = lambda x: dict(old_data_collator(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1348ca1-2d56-480a-98d2-c2a098042052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1140' max='1140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1140/1140 27:28, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.648400</td>\n",
       "      <td>1.948184</td>\n",
       "      <td>0.555214</td>\n",
       "      <td>0.555214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.650300</td>\n",
       "      <td>1.713838</td>\n",
       "      <td>0.598692</td>\n",
       "      <td>0.598692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.315600</td>\n",
       "      <td>1.673530</td>\n",
       "      <td>0.604463</td>\n",
       "      <td>0.604463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_output = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7bac3dca-07ea-4aa0-8e6a-51e767cb49af",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1efd13f4-6359-43c4-9723-014235990223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='164' max='82' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [82/82 01:20]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the F1-Score of validation set is: 0.6045\n"
     ]
    }
   ],
   "source": [
    "pred_output_valid = trainer.predict(dataset[\"valid\"])\n",
    "pred_valid = pred_output_valid.predictions.argmax(axis=-1)\n",
    "valid_f1 = f1_score(dataset[\"valid\"][\"label\"], pred_valid, average=\"micro\")\n",
    "print(f\"the F1-Score of validation set is: {valid_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac4cd06-32dc-4945-8b54-4d632ab40199",
   "metadata": {},
   "source": [
    "# Step 5: Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f9dce2a-0f98-4ee2-a928-af3f49c0aa79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-098ae10728338e6f\n",
      "Reusing dataset json (/home/studio-lab-user/.cache/huggingface/datasets/json/default-098ae10728338e6f/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12a7fb86a131405e811c9322de94217d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dataset = load_dataset(\"json\", data_files=test_filepath)\n",
    "test_dataset = test_dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77fab39b-2ac1-4125-90a8-daf3c4c1f8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/studio-lab-user/.cache/huggingface/datasets/json/default-098ae10728338e6f/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426/cache-4b576133e69525bd.arrow\n"
     ]
    }
   ],
   "source": [
    "test_dataset = test_dataset.map(\n",
    "    lambda batch: tokenizer(batch[\"sentence\"], padding=\"max_length\", truncation=True, max_length=max_length), \n",
    "    batched=True, \n",
    "    batch_size=None, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29b52e5d-226d-460a-8ad2-ce725781ee09",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_output_test = trainer.predict(test_dataset)\n",
    "pred_test = pred_output_test.predictions.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f9c74cd-af26-4f9f-b5a6-2db68a872a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_dataset.to_pandas()[[\"id\"]]\n",
    "test_df[\"label\"] = pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c0c196af-7626-4245-9a85-252ad47665d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"iflytek_predict.json\", \"w\") as fout:\n",
    "    for _, row in test_df.iterrows():\n",
    "        fout.write(json.dumps(row.to_dict()) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b97d3d-7f2a-45af-bafb-d6c8df23bc87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "book:Python",
   "language": "python",
   "name": "conda-env-book-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
